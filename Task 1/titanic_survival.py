# -*- coding: utf-8 -*-
"""Titanic Survival.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qqm71TJQwYcQDnjIUAuPoK-5U3uFyXze
"""

import pandas as pd  # For data manipulation
import numpy as np  # For numerical operations
import seaborn as sns  # For data visualization
import matplotlib.pyplot as plt  # For plotting
from sklearn.model_selection import train_test_split  # For splitting data
from sklearn.preprocessing import LabelEncoder, StandardScaler  # For encoding and scaling
from sklearn.ensemble import RandomForestClassifier  # Machine learning model
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix  # Model evaluation

# Load the dataset
df = pd.read_csv("Titanic-Dataset.csv")

# Display first few rows
df.head()

# Check for missing values
print("Missing Values:\n", df.isnull().sum())

# Fill missing Age values with median age
df['Age'].fillna(df['Age'].median(), inplace=True)

# Fill missing Embarked values with the most common value
df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)

# Drop the 'Cabin' column since it has many missing values
df.drop(columns=['Cabin'], inplace=True)

# Convert categorical variables into numerical format
label_enc = LabelEncoder()
df['Sex'] = label_enc.fit_transform(df['Sex'])  # Male=1, Female=0
df['Embarked'] = label_enc.fit_transform(df['Embarked'])

# Select features and target variable
features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']
target = 'Survived'

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.2, random_state=42)

# Scale the data for better model performance
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Train a RandomForestClassifier model
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

# Visualize feature importance
feature_importance = pd.Series(model.feature_importances_, index=features).sort_values(ascending=False)
plt.figure(figsize=(8, 6))
sns.barplot(x=feature_importance.values, y=feature_importance.index)
plt.xlabel("Importance")
plt.ylabel("Feature")
plt.title("Feature Importance in Titanic Survival Prediction")
plt.show()